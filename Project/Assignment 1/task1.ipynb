{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGpzxALXO3_c"
      },
      "source": [
        "<h1> Task 1 </h1>\n",
        "<h3> 2. Load the three JSON files and encode them as pandas dataframes. </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "WmDePCZ0O3_f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrOeCCeTPBd7",
        "outputId": "45aa49d5-0ed1-49a6-b69c-bde83b602c43"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "1Gnxra7IO3_h"
      },
      "outputs": [],
      "source": [
        "training_url = '/content/drive/MyDrive/Assignment 1/data/training.json'\n",
        "validation_url = '/content/drive/MyDrive/Assignment 1/data/validation.json'\n",
        "test_url = '/content/drive/MyDrive/Assignment 1/data/test.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ABXXeRZyO3_h"
      },
      "outputs": [],
      "source": [
        "training_set = pd.read_json(training_url, orient='index')\n",
        "validation_set = pd.read_json(validation_url, orient='index')\n",
        "test_set = pd.read_json(test_url, orient='index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzrMgWXkO3_i"
      },
      "source": [
        "<h3> 3. Generate hard labels for Task 1 using majority voting and store them in a new dataframe column called `hard_label_task1`. <br>Items without a clear majority will be removed from the dataset. </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "PsmJDOIOO3_j"
      },
      "outputs": [],
      "source": [
        "def majority(l):\n",
        "    y_count = l.count('YES')\n",
        "    n_count = l.count('NO')\n",
        "\n",
        "    if y_count == n_count:\n",
        "        return pd.NaT\n",
        "\n",
        "    if y_count > 3:\n",
        "        return 'YES'\n",
        "\n",
        "    return 'NO'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "s9hxDOWjO3_j"
      },
      "outputs": [],
      "source": [
        "training_set['hard_label_task1'] = training_set['labels_task1'].apply(majority)\n",
        "training_set.dropna(axis=0, inplace=True)\n",
        "\n",
        "validation_set['hard_label_task1'] = validation_set['labels_task1'].apply(majority)\n",
        "validation_set.dropna(axis=0, inplace=True)\n",
        "\n",
        "test_set['hard_label_task1'] = test_set['labels_task1'].apply(majority)\n",
        "test_set.dropna(axis=0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln8PNReUO3_k"
      },
      "source": [
        "<h3> 4. Filter the DataFrame to keep only rows where the `lang` column is `'en'`. </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "t_T5zOiFO3_k"
      },
      "outputs": [],
      "source": [
        "lang = 'en'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "24-3RDlhO3_k"
      },
      "outputs": [],
      "source": [
        "training_set = training_set[training_set['lang'] == lang]\n",
        "validation_set = validation_set[validation_set['lang'] == lang]\n",
        "test_set = test_set[test_set['lang'] == lang]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIC77nNgO3_l"
      },
      "source": [
        "<h3> 5. Remove unwanted columns: Keep only `id_EXIST`, `lang`, `tweet`, and `hard_label_task1`. </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "1USDpIecO3_l"
      },
      "outputs": [],
      "source": [
        "training_set = training_set.loc[:,['id_EXIST', 'lang', 'tweet', 'hard_label_task1']]\n",
        "validation_set = validation_set.loc[:,['id_EXIST', 'lang', 'tweet', 'hard_label_task1']]\n",
        "test_set = test_set.loc[:,['id_EXIST', 'lang', 'tweet', 'hard_label_task1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j39m2p1ZO3_l"
      },
      "source": [
        "<h3> 6. Encode the `hard_label_task1` column: Use 1 to represent \"YES\" and 0 to represent \"NO\".</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "EnhYC0ZIO3_l"
      },
      "outputs": [],
      "source": [
        "training_set['hard_label_task1'] = training_set['hard_label_task1'].map({'YES':1, 'NO':0})\n",
        "validation_set['hard_label_task1'] = validation_set['hard_label_task1'].map({'YES':1, 'NO':0})\n",
        "test_set['hard_label_task1'] = test_set['hard_label_task1'].map({'YES':1, 'NO':0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "XWhi7JeKO3_l",
        "outputId": "6dc460e7-ae8d-4401-c6a6-8ab06a77e67b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id_EXIST lang                                              tweet  \\\n",
              "200002    200002   en  Writing a uni essay in my local pub with a cof...   \n",
              "200003    200003   en  @UniversalORL it is 2021 not 1921. I dont appr...   \n",
              "200006    200006   en  According to a customer I have plenty of time ...   \n",
              "200007    200007   en  So only 'blokes' drink beer? Sorry, but if you...   \n",
              "200008    200008   en  New to the shelves this week - looking forward...   \n",
              "...          ...  ...                                                ...   \n",
              "203256    203256   en  idk why y’all bitches think having half your a...   \n",
              "203257    203257   en  This has been a part of an experiment with @Wo...   \n",
              "203258    203258   en  \"Take me already\" \"Not yet. You gotta be ready...   \n",
              "203259    203259   en  @clintneedcoffee why do you look like a whore?...   \n",
              "203260    203260   en  ik when mandy says “you look like a whore” i l...   \n",
              "\n",
              "        hard_label_task1  \n",
              "200002                 1  \n",
              "200003                 1  \n",
              "200006                 1  \n",
              "200007                 1  \n",
              "200008                 0  \n",
              "...                  ...  \n",
              "203256                 1  \n",
              "203257                 1  \n",
              "203258                 1  \n",
              "203259                 1  \n",
              "203260                 1  \n",
              "\n",
              "[2870 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c52f9c29-18a8-4395-b3d3-e12fcb7bf324\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_EXIST</th>\n",
              "      <th>lang</th>\n",
              "      <th>tweet</th>\n",
              "      <th>hard_label_task1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200002</th>\n",
              "      <td>200002</td>\n",
              "      <td>en</td>\n",
              "      <td>Writing a uni essay in my local pub with a cof...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200003</th>\n",
              "      <td>200003</td>\n",
              "      <td>en</td>\n",
              "      <td>@UniversalORL it is 2021 not 1921. I dont appr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200006</th>\n",
              "      <td>200006</td>\n",
              "      <td>en</td>\n",
              "      <td>According to a customer I have plenty of time ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200007</th>\n",
              "      <td>200007</td>\n",
              "      <td>en</td>\n",
              "      <td>So only 'blokes' drink beer? Sorry, but if you...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200008</th>\n",
              "      <td>200008</td>\n",
              "      <td>en</td>\n",
              "      <td>New to the shelves this week - looking forward...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203256</th>\n",
              "      <td>203256</td>\n",
              "      <td>en</td>\n",
              "      <td>idk why y’all bitches think having half your a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203257</th>\n",
              "      <td>203257</td>\n",
              "      <td>en</td>\n",
              "      <td>This has been a part of an experiment with @Wo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203258</th>\n",
              "      <td>203258</td>\n",
              "      <td>en</td>\n",
              "      <td>\"Take me already\" \"Not yet. You gotta be ready...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203259</th>\n",
              "      <td>203259</td>\n",
              "      <td>en</td>\n",
              "      <td>@clintneedcoffee why do you look like a whore?...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203260</th>\n",
              "      <td>203260</td>\n",
              "      <td>en</td>\n",
              "      <td>ik when mandy says “you look like a whore” i l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2870 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c52f9c29-18a8-4395-b3d3-e12fcb7bf324')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c52f9c29-18a8-4395-b3d3-e12fcb7bf324 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c52f9c29-18a8-4395-b3d3-e12fcb7bf324');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2447e278-191c-4244-a6ee-777cd36d51ce\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2447e278-191c-4244-a6ee-777cd36d51ce')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2447e278-191c-4244-a6ee-777cd36d51ce button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_81c7da1e-0ece-406a-bbcc-3b4f56b543b5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('training_set')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_81c7da1e-0ece-406a-bbcc-3b4f56b543b5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('training_set');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "training_set",
              "summary": "{\n  \"name\": \"training_set\",\n  \"rows\": 2870,\n  \"fields\": [\n    {\n      \"column\": \"id_EXIST\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 934,\n        \"min\": 200002,\n        \"max\": 203260,\n        \"num_unique_values\": 2870,\n        \"samples\": [\n          200504,\n          202694,\n          200852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2870,\n        \"samples\": [\n          \"Call me sexist but it just feels wrong that women are reffing the NBA like go ref the WNBA\\ud83d\\ude2c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hard_label_task1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "training_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9r67IJTO3_m"
      },
      "source": [
        "<h1> Task 2 </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djzkN4SrO3_m"
      },
      "source": [
        "- **Remove emojis** from the tweets.\n",
        "- **Remove hashtags** (e.g., `#example`).\n",
        "- **Remove mentions** such as `@user`.\n",
        "- **Remove URLs** from the tweets.\n",
        "- **Remove special characters and symbols**.\n",
        "- **Remove specific quote characters** (e.g., curly quotes).\n",
        "- **Perform lemmatization** to reduce words to their base form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUmZWeqzO3_m",
        "outputId": "05729684-e40f-4681-af33-87eb10a73465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji\n",
        "\n",
        "import re\n",
        "import emoji\n",
        "from nltk.corpus import stopwords\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "R6-6_f7VO3_n"
      },
      "outputs": [],
      "source": [
        "emojis_list = map(lambda x: ''.join(x.split()), emoji.EMOJI_DATA.keys())\n",
        "\n",
        "EMOJI_RE = re.compile('|'.join(re.escape(p) for p in emojis_list))\n",
        "HASHTAGS_RE = re.compile('#\\w+')\n",
        "MENTIONS_RE = re.compile('@\\w+')\n",
        "URL_RE = re.compile('(https|http)?:\\/\\/\\S+')\n",
        "#Qui ho aggiunto il punto sostituito dallo spazio perchè mi sembra che la maggior parte\n",
        "#dei tweets ne traggono beneficio, poi TODO va provato raga\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|,;‘’“”\\\"\\.]')\n",
        "SPECIAL_CHARACTERS_RE = re.compile('&amp;')\n",
        "GOOD_SYMBOLS_RE = re.compile('[^\\w+ +]')\n",
        "\n",
        "try:\n",
        "    STOPWORDS = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "    STOPWORDS = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "aiar3s09O3_n"
      },
      "outputs": [],
      "source": [
        "def lower(text: str) -> str:\n",
        "    return text.lower()\n",
        "\n",
        "def remove_emojis(text: str) -> str:\n",
        "    return EMOJI_RE.sub(' ',text)\n",
        "\n",
        "def remove_hashtags(text: str) -> str:\n",
        "    return HASHTAGS_RE.sub(' ', text)\n",
        "\n",
        "def remove_mentions(text: str) -> str:\n",
        "    return MENTIONS_RE.sub(' ', text)\n",
        "\n",
        "def remove_url(text: str) -> str:\n",
        "    return URL_RE.sub(' ',text)\n",
        "\n",
        "def remove_special_characters(text: str) -> str:\n",
        "    return SPECIAL_CHARACTERS_RE.sub('', text)\n",
        "\n",
        "def replace_special_characters(text: str) -> str:\n",
        "    return REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "\n",
        "def filter_out_uncommon_symbols(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes any special character that is not in the good symbols list (check regular expression)\n",
        "    \"\"\"\n",
        "    return GOOD_SYMBOLS_RE.sub('', text)\n",
        "\n",
        "def remove_stopwords(text: str) -> str:\n",
        "    return ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n",
        "\n",
        "def strip_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes any left or right spacing (including carriage return) from text.\n",
        "    \"\"\"\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncKwO6yO3_n"
      },
      "source": [
        "We can observe that some hashtags in the form \"#somethinghttps://\" also removes the initial part of the link."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAnHByb3O3_n"
      },
      "source": [
        "@rufinelix's account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "EXkeuKHpO3_o"
      },
      "outputs": [],
      "source": [
        "from typing import List, Callable, Dict\n",
        "from functools import reduce\n",
        "\n",
        "PREPROCESSING_PIPELINE = [\n",
        "                          lower,\n",
        "                          remove_emojis,\n",
        "                          remove_hashtags,\n",
        "                          remove_mentions,\n",
        "                          remove_url,\n",
        "                          remove_special_characters,\n",
        "                          replace_special_characters,\n",
        "                          filter_out_uncommon_symbols,\n",
        "                          remove_stopwords,\n",
        "                          strip_text\n",
        "                          ]\n",
        "#Lui elimina anche le stopwords, poi TODO va provato raga\n",
        "\n",
        "def text_prepare(text: str,\n",
        "                 filter_methods: List[Callable[[str], str]] = None) -> str:\n",
        "    \"\"\"\n",
        "    Applies a list of pre-processing functions in sequence (reduce).\n",
        "    Note that the order is important here!\n",
        "    \"\"\"\n",
        "    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n",
        "    return reduce(lambda txt, f: f(txt), filter_methods, text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmtdMboIO3_o",
        "outputId": "49ce735c-eab5-46f2-d663-df3beaa9dd26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-processing text...\n",
            "\n",
            "[Debug] Before:\n",
            "According to a customer I have plenty of time to go spent the Stirling coins he wants to pay me with, in Derry. \"Just like any other woman, I'm sure of it.\" #EveryDaySexism in retail.\n",
            "\n",
            "[Debug] After:\n",
            "according customer plenty time go spent stirling coins wants pay derry like woman im sure retail\n",
            "\n",
            "Pre-processing completed!\n"
          ]
        }
      ],
      "source": [
        "print('Pre-processing text...')\n",
        "\n",
        "print()\n",
        "print(f'[Debug] Before:\\n{training_set.tweet.values[2]}')\n",
        "print()\n",
        "\n",
        "# Replace each sentence with its pre-processed version\n",
        "training_set['tweet'] = training_set['tweet'].apply(lambda txt: text_prepare(txt))\n",
        "validation_set['tweet'] = validation_set['tweet'].apply(lambda txt: text_prepare(txt))\n",
        "test_set['tweet'] = test_set['tweet'].apply(lambda txt: text_prepare(txt))\n",
        "\n",
        "print(f'[Debug] After:\\n{training_set.tweet.values[2]}')\n",
        "print()\n",
        "\n",
        "print(\"Pre-processing completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "ZWo94S5MO3_o",
        "outputId": "956762b5-2547-47c0-a48d-0c04684bf318"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200002    writing uni essay local pub coffee random old ...\n",
              "200003    2021 1921 dont appreciate two rides team membe...\n",
              "200006    according customer plenty time go spent stirli...\n",
              "200007    blokes drink beer sorry arent bloke drink wine...\n",
              "200008       new shelves week looking forward reading books\n",
              "200010                      guess fairly normal neanderthal\n",
              "200011    means women usually end lower paid support wor...\n",
              "200013    hi orla interesting piece 2 policy response be...\n",
              "200015    dear god colette capable identifying sexism li...\n",
              "200016                            women home cooking family\n",
              "Name: tweet, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200002</th>\n",
              "      <td>writing uni essay local pub coffee random old ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200003</th>\n",
              "      <td>2021 1921 dont appreciate two rides team membe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200006</th>\n",
              "      <td>according customer plenty time go spent stirli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200007</th>\n",
              "      <td>blokes drink beer sorry arent bloke drink wine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200008</th>\n",
              "      <td>new shelves week looking forward reading books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200010</th>\n",
              "      <td>guess fairly normal neanderthal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200011</th>\n",
              "      <td>means women usually end lower paid support wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200013</th>\n",
              "      <td>hi orla interesting piece 2 policy response be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200015</th>\n",
              "      <td>dear god colette capable identifying sexism li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200016</th>\n",
              "      <td>women home cooking family</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "#Focus Focus Focus qui le contrazioni tipo I'm le accorpa, ma sotto la lemmatization con wordNet le\n",
        "#scoppia. Se usassimo le stopwords le eliminerebbe direttamente e il problema non si porrebbe, quindi indovinate\n",
        "#TODO va provato raga\n",
        "training_set.iloc[:10]['tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_a7AzM6O3_o",
        "outputId": "7b2e1816-84fb-4f76-9468-1136c2e931ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokenizer = WhitespaceTokenizer()\n",
        "\n",
        "def get_wordnet_key(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return 'n'\n",
        "\n",
        "def lem_text(text: str):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tagged = pos_tag(tokens)\n",
        "    words = [lemmatizer.lemmatize(word, get_wordnet_key(tag)) for word, tag in tagged]\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "Wa8xcbcAO3_o",
        "outputId": "9bc0370b-0636-4706-dde4-341ef282aebd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200002    writing uni essay local pub coffee random old ...\n",
              "200003    2021 1921 dont appreciate two rides team membe...\n",
              "200006    according customer plenty time go spent stirli...\n",
              "200007    blokes drink beer sorry arent bloke drink wine...\n",
              "200008       new shelves week looking forward reading books\n",
              "200010                      guess fairly normal neanderthal\n",
              "200011    means women usually end lower paid support wor...\n",
              "200013    hi orla interesting piece 2 policy response be...\n",
              "200015    dear god colette capable identifying sexism li...\n",
              "200016                            women home cooking family\n",
              "Name: tweet, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200002</th>\n",
              "      <td>writing uni essay local pub coffee random old ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200003</th>\n",
              "      <td>2021 1921 dont appreciate two rides team membe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200006</th>\n",
              "      <td>according customer plenty time go spent stirli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200007</th>\n",
              "      <td>blokes drink beer sorry arent bloke drink wine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200008</th>\n",
              "      <td>new shelves week looking forward reading books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200010</th>\n",
              "      <td>guess fairly normal neanderthal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200011</th>\n",
              "      <td>means women usually end lower paid support wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200013</th>\n",
              "      <td>hi orla interesting piece 2 policy response be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200015</th>\n",
              "      <td>dear god colette capable identifying sexism li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200016</th>\n",
              "      <td>women home cooking family</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "training_set['tweet'][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "tPV1wPaGO3_p"
      },
      "outputs": [],
      "source": [
        "lem_train_texts = [lem_text(text) for text in training_set['tweet']]\n",
        "lem_validation_texts = [lem_text(text) for text in validation_set['tweet']]\n",
        "lem_test_texts = [lem_text(text) for text in test_set['tweet']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkFXXPRJO3_p",
        "outputId": "5c03173f-f5cb-48c1-bb65-2de745c14e3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['write uni essay local pub coffee random old man keep ask drunk question im try concentrate end good luck youll end get marry use anyway alive well',\n",
              " '2021 1921 dont appreciate two ride team member look behind ask man behind many party impress',\n",
              " 'accord customer plenty time go spent stirling coin want pay derry like woman im sure retail',\n",
              " 'bloke drink beer sorry arent bloke drink wine apparently alive well',\n",
              " 'new shelf week look forward read book',\n",
              " 'guess fairly normal neanderthal',\n",
              " 'mean woman usually end low pay support work start change traditionalist notice unfairness previously hasnt bother',\n",
              " 'hi orla interest piece 2 policy response believe earlyinlife prosecution punishment way go boy young men offend girl woman see zero tolerance approach institute',\n",
              " 'dear god colette capable identify sexism literally anywhere good see develop female grandpa simpson',\n",
              " 'woman home cooking family']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "lem_train_texts[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "cNzqL_0HO3_p"
      },
      "outputs": [],
      "source": [
        "training_set['tweet'] = lem_train_texts\n",
        "validation_set['tweet'] = lem_validation_texts\n",
        "test_set['tweet'] = lem_test_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AXZOPpcO3_p"
      },
      "source": [
        "<h1> Task 3 </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNOwfJzQO3_p"
      },
      "source": [
        "Embed words using **GloVe embeddings**. <br>\n",
        "You are **free** to pick any embedding dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "46QHfuNOO3_p"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Ug25Ior2O3_q"
      },
      "outputs": [],
      "source": [
        "def build_vocabulary(df: pd.DataFrame) -> (Dict[int, str], Dict[str, int], List[str]):\n",
        "    \"\"\"\n",
        "    Given a dataset, builds the corresponding word vocabulary.\n",
        "\n",
        "    :param df: dataset from which we want to build the word vocabulary (pandas.DataFrame)\n",
        "    :return:\n",
        "      - word vocabulary: vocabulary index to word\n",
        "      - inverse word vocabulary: word to vocabulary index\n",
        "      - word listing: set of unique terms that build up the vocabulary\n",
        "    \"\"\"\n",
        "    idx_to_word = OrderedDict()\n",
        "    word_to_idx = OrderedDict()\n",
        "\n",
        "    curr_idx = 0\n",
        "    for sentence in df.tweet:\n",
        "        tokens = sentence.split()\n",
        "        for token in tokens:\n",
        "            if token not in word_to_idx:\n",
        "                word_to_idx[token] = curr_idx\n",
        "                idx_to_word[curr_idx] = token\n",
        "                curr_idx += 1\n",
        "\n",
        "    word_to_idx['UNK'] = curr_idx\n",
        "    idx_to_word[curr_idx] = 'UNK'\n",
        "\n",
        "    word_listing = list(idx_to_word.values())\n",
        "    return idx_to_word, word_to_idx, word_listing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsVDtwr1O3_q",
        "outputId": "19869ed4-9668-4a65-fda4-033cf74345c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Debug] Index -> Word vocabulary size: 9363\n",
            "[Debug] Word -> Index vocabulary size: 9363\n",
            "[Debug] Some words: [('uni', 1), ('essay', 2), ('local', 3), ('pub', 4), ('coffee', 5), ('random', 6), ('old', 7), ('man', 8), ('keep', 9), ('ask', 10)]\n"
          ]
        }
      ],
      "source": [
        "idx_to_word, word_to_idx, word_listing = build_vocabulary(training_set)\n",
        "print(f'[Debug] Index -> Word vocabulary size: {len(idx_to_word)}')\n",
        "print(f'[Debug] Word -> Index vocabulary size: {len(word_to_idx)}')\n",
        "print(f'[Debug] Some words: {[(idx_to_word[idx], idx) for idx in np.arange(10) + 1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "bqLbEcDRO3_q"
      },
      "outputs": [],
      "source": [
        "idx_to_word, word_to_idx, word_listing = build_vocabulary(training_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "BPsCG_RhO3_q"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import gensim.downloader as gloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "DduFQdEHO3_q"
      },
      "outputs": [],
      "source": [
        "embedding_dimension = 50\n",
        "download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
        "emb_model = gloader.load(download_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "J262jvDjO3_q"
      },
      "outputs": [],
      "source": [
        "def check_OOV_terms(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                    word_listing: List[str]):\n",
        "    \"\"\"\n",
        "    Checks differences between pre-trained embedding model vocabulary\n",
        "    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_listing: dataset specific vocabulary (list)\n",
        "\n",
        "    :return\n",
        "        - list of OOV terms\n",
        "    \"\"\"\n",
        "    embedding_vocabulary = set(embedding_model.key_to_index.keys())\n",
        "    oov = set(word_listing).difference(embedding_vocabulary)\n",
        "    return list(oov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntyweYSJO3_v",
        "outputId": "2556ab36-24d3-4fff-ffe1-31690f5b35e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms: 1340 (14.31%)\n"
          ]
        }
      ],
      "source": [
        "oov_terms = check_OOV_terms(emb_model, word_listing)\n",
        "oov_percentage = float(len(oov_terms)) * 100 / len(word_listing)\n",
        "print(f\"Total OOV terms: {len(oov_terms)} ({oov_percentage:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Um9Gby5PO3_v"
      },
      "outputs": [],
      "source": [
        "def build_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                           embedding_dimension: int,\n",
        "                           word_to_idx: Dict[str, int],\n",
        "                           vocab_size: int,\n",
        "                           oov_terms: List[str]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Builds the embedding matrix of a specific dataset given a pre-trained word embedding model\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_to_idx: vocabulary map (word -> index) (dict)\n",
        "    :param vocab_size: size of the vocabulary\n",
        "    :param oov_terms: list of OOV terms (list)\n",
        "\n",
        "    :return\n",
        "        - embedding matrix that assigns a high dimensional vector to each word in the dataset specific vocabulary (shape |V| x d)\n",
        "    \"\"\"\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dimension), dtype=np.float32)\n",
        "    for word, idx in word_to_idx.items():\n",
        "        try:\n",
        "            embedding_vector = embedding_model[word]\n",
        "        except (KeyError, TypeError):\n",
        "            embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
        "\n",
        "        embedding_matrix[idx] = embedding_vector\n",
        "\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E06W4seQO3_v",
        "outputId": "8456c48f-795e-48e6-aba1-d4527e201ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix shape: (9363, 50)\n"
          ]
        }
      ],
      "source": [
        "embedding_matrix = build_embedding_matrix(emb_model, embedding_dimension, word_to_idx, len(word_to_idx), oov_terms)\n",
        "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating an extra column for each dataset to store all the token ids"
      ],
      "metadata": {
        "id": "UzYggMVKm-7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(sentence: str, word_to_idx: Dict[str, int]) -> List[int]:\n",
        "    \"\"\"\n",
        "    Maps tokens in a sentence to vocabulary indices, replacing OOV terms with 'UNK'.\n",
        "\n",
        "    :param sentence: input sentence (str)\n",
        "    :param word_to_idx: word-to-index mapping (dict)\n",
        "    :return: list of token indices (list of int)\n",
        "    \"\"\"\n",
        "    tokens = sentence.split()\n",
        "    return [word_to_idx.get(token, word_to_idx['UNK']) for token in tokens]\n",
        "\n",
        "training_set['processed'] = training_set['tweet'].apply(\n",
        "    lambda x: preprocess_text(x, word_to_idx)\n",
        ")\n",
        "\n",
        "# Validation/Test: Preprocess to handle OOV terms\n",
        "validation_set['processed'] = validation_set['tweet'].apply(\n",
        "    lambda x: preprocess_text(x, word_to_idx)\n",
        ")\n",
        "test_set['processed'] = test_set['tweet'].apply(\n",
        "    lambda x: preprocess_text(x, word_to_idx)\n",
        ")\n",
        "\n",
        "# Inspect a test sentence\n",
        "print(\"Original:\", test_set['tweet'].iloc[0])\n",
        "print(\"Processed indices:\", test_set['processed'].iloc[0])\n",
        "print(\"Embedding for 'UNK':\", embedding_matrix[word_to_idx['UNK']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNOO6ZDgItPu",
        "outputId": "9cb72342-f7b9-4773-b469-b1e2d49fd1da"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: 1st day pool beautiful sunday ny bad dare go due frigid water temp last 45 min figure prove point\n",
            "Processed indices: [5076, 299, 9094, 1952, 1176, 2871, 432, 2310, 43, 668, 4916, 4763, 4990, 1055, 9362, 2277, 775, 479, 534]\n",
            "Embedding for 'UNK': [ 0.01806087 -0.00517448 -0.03251405  0.02877776 -0.01102105  0.01444829\n",
            "  0.03964875 -0.03559718  0.02460842 -0.04382962  0.01952896 -0.01317036\n",
            "  0.04516917  0.0422252   0.02840588  0.02411183 -0.0449602   0.01511133\n",
            " -0.01043571 -0.0226937   0.01184831  0.03518415 -0.00442959  0.04760322\n",
            " -0.02000306 -0.0315448   0.02480833 -0.0203414  -0.02227696  0.04458721\n",
            "  0.04528634 -0.01116554  0.00918736  0.01863066 -0.03175552 -0.00786053\n",
            " -0.0239286  -0.04398062 -0.03539643  0.01477463 -0.04517939 -0.01180867\n",
            " -0.04244076 -0.00156193  0.0477278   0.01793771 -0.03798958  0.01222676\n",
            "  0.00223762 -0.01398266]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set['processed']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "olw_dH8TaB-L",
        "outputId": "3c7fa8af-c43b-480d-c7bd-3cb749cf02a1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200002    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...\n",
              "200003    [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 10, 8...\n",
              "200006    [39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5...\n",
              "200007         [54, 55, 56, 57, 58, 54, 55, 59, 60, 24, 25]\n",
              "200008                         [61, 62, 63, 34, 64, 65, 66]\n",
              "                                ...                        \n",
              "203256    [902, 271, 523, 1084, 1708, 1827, 1919, 34, 50...\n",
              "203257    [263, 3537, 13, 990, 1098, 2181, 1362, 6513, 3...\n",
              "203258    [623, 361, 705, 188, 1151, 13, 6401, 370, 6380...\n",
              "203259                                 [34, 50, 2238, 9360]\n",
              "203260       [5278, 9361, 370, 34, 50, 2238, 34, 1919, 835]\n",
              "Name: processed, Length: 2870, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200002</th>\n",
              "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200003</th>\n",
              "      <td>[26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 10, 8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200006</th>\n",
              "      <td>[39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200007</th>\n",
              "      <td>[54, 55, 56, 57, 58, 54, 55, 59, 60, 24, 25]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200008</th>\n",
              "      <td>[61, 62, 63, 34, 64, 65, 66]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203256</th>\n",
              "      <td>[902, 271, 523, 1084, 1708, 1827, 1919, 34, 50...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203257</th>\n",
              "      <td>[263, 3537, 13, 990, 1098, 2181, 1362, 6513, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203258</th>\n",
              "      <td>[623, 361, 705, 188, 1151, 13, 6401, 370, 6380...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203259</th>\n",
              "      <td>[34, 50, 2238, 9360]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203260</th>\n",
              "      <td>[5278, 9361, 370, 34, 50, 2238, 34, 1919, 835]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2870 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0vfIQTxbJ2O",
        "outputId": "3528fc45-02bf-4762-cc4f-6ca152bb2245"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.065611  ,  0.18878   ,  0.38947   , ...,  0.50332   ,\n",
              "        -0.37874   ,  0.78717   ],\n",
              "       [-0.48424   ,  0.10052   , -0.20392   , ...,  0.528     ,\n",
              "         0.47025   , -0.099937  ],\n",
              "       [-0.73514   ,  1.0877    , -1.0185    , ...,  0.40231   ,\n",
              "         0.07081   ,  0.24598   ],\n",
              "       ...,\n",
              "       [ 0.94112   ,  0.072009  ,  0.054059  , ..., -1.035     ,\n",
              "        -0.1885    ,  0.35589   ],\n",
              "       [ 0.17566   ,  0.40873   , -0.3003    , ..., -0.67123   ,\n",
              "        -0.91092   ,  0.88043   ],\n",
              "       [ 0.01806087, -0.00517448, -0.03251405, ...,  0.01222676,\n",
              "         0.00223762, -0.01398266]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElRAMGFAO3_w"
      },
      "source": [
        "<h1> TASK 4 </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v5aNs3fO3_w"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
        "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
        "\n",
        "* **Model 1**: add an additional LSTM layer to the Baseline model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "jnIgIG7CO3_w"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM, Bidirectional, Dense, Embedding\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Padding sentences to achieve the same length for each of them"
      ],
      "metadata": {
        "id": "BDXkjQa-mw9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_length = 100  # Define maximum sequence length\n",
        "train_padded = pad_sequences(training_set['processed'], maxlen=max_length, padding='post')\n",
        "validation_padded = pad_sequences(validation_set['processed'], maxlen=max_length, padding='post')\n",
        "test_padded = pad_sequences(test_set['processed'], maxlen=max_length, padding='post')"
      ],
      "metadata": {
        "id": "nGR4UQoverNs"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline"
      ],
      "metadata": {
        "id": "qDIvgPLFMdg_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "yA_MgEuqO3_w"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(word_to_idx)\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "                            input_dim=vocab_size,\n",
        "                            output_dim=embedding_dimension,\n",
        "                            weights=[embedding_matrix],\n",
        "                            mask_zero=True,                   # automatically masks padding tokens\n",
        "                            name='encoder_embedding'\n",
        "                            #trainable=False\n",
        "                            )\n",
        "\n",
        "# defining a bidirectional LSTM\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_padded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x01dfVO-fj9f",
        "outputId": "785acd24-16b2-405d-f9cd-1309e8577ca2"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2870, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) #binary because we have a binary classification task\n",
        "model.fit(train_padded, training_set['hard_label_task1'], epochs=10, batch_size=32, validation_data=(validation_padded, validation_set['hard_label_task1']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD8T0ErTOLFp",
        "outputId": "bed2fdb0-0bcf-4d6e-f89f-00c38a756577"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - accuracy: 0.6155 - loss: 0.6358 - val_accuracy: 0.7468 - val_loss: 0.5123\n",
            "Epoch 2/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - accuracy: 0.7617 - loss: 0.5035 - val_accuracy: 0.7595 - val_loss: 0.4720\n",
            "Epoch 3/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 169ms/step - accuracy: 0.8249 - loss: 0.4011 - val_accuracy: 0.7848 - val_loss: 0.4375\n",
            "Epoch 4/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 173ms/step - accuracy: 0.8690 - loss: 0.3258 - val_accuracy: 0.7911 - val_loss: 0.4737\n",
            "Epoch 5/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 157ms/step - accuracy: 0.9065 - loss: 0.2418 - val_accuracy: 0.7722 - val_loss: 0.5491\n",
            "Epoch 6/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 163ms/step - accuracy: 0.9429 - loss: 0.1596 - val_accuracy: 0.8291 - val_loss: 0.4136\n",
            "Epoch 7/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 163ms/step - accuracy: 0.9775 - loss: 0.0840 - val_accuracy: 0.8038 - val_loss: 0.4736\n",
            "Epoch 8/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - accuracy: 0.9770 - loss: 0.0695 - val_accuracy: 0.7848 - val_loss: 0.5440\n",
            "Epoch 9/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.9850 - loss: 0.0509 - val_accuracy: 0.8291 - val_loss: 0.5812\n",
            "Epoch 10/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 161ms/step - accuracy: 0.9952 - loss: 0.0281 - val_accuracy: 0.8228 - val_loss: 0.7574\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c48c9ada380>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1"
      ],
      "metadata": {
        "id": "0Mt3WomtMiVP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gd8QJHWpMl6A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}