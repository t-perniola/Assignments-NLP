{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGpzxALXO3_c"
      },
      "source": [
        "<h1> Task 1 </h1>\n",
        "<h3> 2. Load the three JSON files and encode them as pandas dataframes. </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmDePCZ0O3_f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrOeCCeTPBd7",
        "outputId": "fc23dc31-c825-486a-c7ff-3665454d69c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Gnxra7IO3_h"
      },
      "outputs": [],
      "source": [
        "training_url = '/content/drive/MyDrive/Assignment 1/data/training.json'\n",
        "validation_url = '/content/drive/MyDrive/Assignment 1/data/validation.json'\n",
        "test_url = '/content/drive/MyDrive/Assignment 1/data/test.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABXXeRZyO3_h"
      },
      "outputs": [],
      "source": [
        "training_set = pd.read_json(training_url, orient='index')\n",
        "validation_set = pd.read_json(validation_url, orient='index')\n",
        "test_set = pd.read_json(test_url, orient='index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzrMgWXkO3_i"
      },
      "source": [
        "<h3> 3. Generate hard labels for Task 1 using majority voting and store them in a new dataframe column called `hard_label_task1`. <br>Items without a clear majority will be removed from the dataset. </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsmJDOIOO3_j"
      },
      "outputs": [],
      "source": [
        "def majority(l):\n",
        "    y_count = l.count('YES')\n",
        "    n_count = l.count('NO')\n",
        "\n",
        "    if y_count == n_count:\n",
        "        return pd.NaT\n",
        "\n",
        "    if y_count > 3:\n",
        "        return 'YES'\n",
        "\n",
        "    return 'NO'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9hxDOWjO3_j"
      },
      "outputs": [],
      "source": [
        "training_set['hard_label_task1'] = training_set['labels_task1'].apply(majority)\n",
        "training_set.dropna(axis=0, inplace=True)\n",
        "\n",
        "validation_set['hard_label_task1'] = validation_set['labels_task1'].apply(majority)\n",
        "validation_set.dropna(axis=0, inplace=True)\n",
        "\n",
        "test_set['hard_label_task1'] = test_set['labels_task1'].apply(majority)\n",
        "test_set.dropna(axis=0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln8PNReUO3_k"
      },
      "source": [
        "<h3> 4. Filter the DataFrame to keep only rows where the `lang` column is `'en'`. </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_T5zOiFO3_k"
      },
      "outputs": [],
      "source": [
        "lang = 'en'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24-3RDlhO3_k"
      },
      "outputs": [],
      "source": [
        "training_set = training_set[training_set['lang'] == lang]\n",
        "validation_set = validation_set[validation_set['lang'] == lang]\n",
        "test_set = test_set[test_set['lang'] == lang]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIC77nNgO3_l"
      },
      "source": [
        "<h3> 5. Remove unwanted columns: Keep only `id_EXIST`, `lang`, `tweet`, and `hard_label_task1`. </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1USDpIecO3_l"
      },
      "outputs": [],
      "source": [
        "training_set = training_set.loc[:,['id_EXIST', 'lang', 'tweet', 'hard_label_task1']]\n",
        "validation_set = validation_set.loc[:,['id_EXIST', 'lang', 'tweet', 'hard_label_task1']]\n",
        "test_set = test_set.loc[:,['id_EXIST', 'lang', 'tweet', 'hard_label_task1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j39m2p1ZO3_l"
      },
      "source": [
        "<h3> 6. Encode the `hard_label_task1` column: Use 1 to represent \"YES\" and 0 to represent \"NO\".</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnhYC0ZIO3_l"
      },
      "outputs": [],
      "source": [
        "training_set['hard_label_task1'] = training_set['hard_label_task1'].map({'YES':1, 'NO':0})\n",
        "validation_set['hard_label_task1'] = validation_set['hard_label_task1'].map({'YES':1, 'NO':0})\n",
        "test_set['hard_label_task1'] = test_set['hard_label_task1'].map({'YES':1, 'NO':0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "XWhi7JeKO3_l",
        "outputId": "c78a56bf-123e-4926-9cff-d1779bd27f3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id_EXIST lang                                              tweet  \\\n",
              "200002    200002   en  Writing a uni essay in my local pub with a cof...   \n",
              "200003    200003   en  @UniversalORL it is 2021 not 1921. I dont appr...   \n",
              "200006    200006   en  According to a customer I have plenty of time ...   \n",
              "200007    200007   en  So only 'blokes' drink beer? Sorry, but if you...   \n",
              "200008    200008   en  New to the shelves this week - looking forward...   \n",
              "...          ...  ...                                                ...   \n",
              "203256    203256   en  idk why y’all bitches think having half your a...   \n",
              "203257    203257   en  This has been a part of an experiment with @Wo...   \n",
              "203258    203258   en  \"Take me already\" \"Not yet. You gotta be ready...   \n",
              "203259    203259   en  @clintneedcoffee why do you look like a whore?...   \n",
              "203260    203260   en  ik when mandy says “you look like a whore” i l...   \n",
              "\n",
              "        hard_label_task1  \n",
              "200002                 1  \n",
              "200003                 1  \n",
              "200006                 1  \n",
              "200007                 1  \n",
              "200008                 0  \n",
              "...                  ...  \n",
              "203256                 1  \n",
              "203257                 1  \n",
              "203258                 1  \n",
              "203259                 1  \n",
              "203260                 1  \n",
              "\n",
              "[2870 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-269c00ce-e196-46ba-9434-7239212b5cc3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_EXIST</th>\n",
              "      <th>lang</th>\n",
              "      <th>tweet</th>\n",
              "      <th>hard_label_task1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200002</th>\n",
              "      <td>200002</td>\n",
              "      <td>en</td>\n",
              "      <td>Writing a uni essay in my local pub with a cof...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200003</th>\n",
              "      <td>200003</td>\n",
              "      <td>en</td>\n",
              "      <td>@UniversalORL it is 2021 not 1921. I dont appr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200006</th>\n",
              "      <td>200006</td>\n",
              "      <td>en</td>\n",
              "      <td>According to a customer I have plenty of time ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200007</th>\n",
              "      <td>200007</td>\n",
              "      <td>en</td>\n",
              "      <td>So only 'blokes' drink beer? Sorry, but if you...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200008</th>\n",
              "      <td>200008</td>\n",
              "      <td>en</td>\n",
              "      <td>New to the shelves this week - looking forward...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203256</th>\n",
              "      <td>203256</td>\n",
              "      <td>en</td>\n",
              "      <td>idk why y’all bitches think having half your a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203257</th>\n",
              "      <td>203257</td>\n",
              "      <td>en</td>\n",
              "      <td>This has been a part of an experiment with @Wo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203258</th>\n",
              "      <td>203258</td>\n",
              "      <td>en</td>\n",
              "      <td>\"Take me already\" \"Not yet. You gotta be ready...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203259</th>\n",
              "      <td>203259</td>\n",
              "      <td>en</td>\n",
              "      <td>@clintneedcoffee why do you look like a whore?...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203260</th>\n",
              "      <td>203260</td>\n",
              "      <td>en</td>\n",
              "      <td>ik when mandy says “you look like a whore” i l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2870 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-269c00ce-e196-46ba-9434-7239212b5cc3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-269c00ce-e196-46ba-9434-7239212b5cc3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-269c00ce-e196-46ba-9434-7239212b5cc3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-871a280d-bd60-4b65-8a4f-a29ff98e5598\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-871a280d-bd60-4b65-8a4f-a29ff98e5598')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-871a280d-bd60-4b65-8a4f-a29ff98e5598 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_071b9ad3-aadb-4d0c-8938-3c4ad562cd7e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('training_set')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_071b9ad3-aadb-4d0c-8938-3c4ad562cd7e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('training_set');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "training_set",
              "summary": "{\n  \"name\": \"training_set\",\n  \"rows\": 2870,\n  \"fields\": [\n    {\n      \"column\": \"id_EXIST\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 934,\n        \"min\": 200002,\n        \"max\": 203260,\n        \"num_unique_values\": 2870,\n        \"samples\": [\n          200504,\n          202694,\n          200852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2870,\n        \"samples\": [\n          \"Call me sexist but it just feels wrong that women are reffing the NBA like go ref the WNBA\\ud83d\\ude2c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hard_label_task1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "training_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9r67IJTO3_m"
      },
      "source": [
        "<h1> Task 2 </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djzkN4SrO3_m"
      },
      "source": [
        "- **Remove emojis** from the tweets.\n",
        "- **Remove hashtags** (e.g., `#example`).\n",
        "- **Remove mentions** such as `@user`.\n",
        "- **Remove URLs** from the tweets.\n",
        "- **Remove special characters and symbols**.\n",
        "- **Remove specific quote characters** (e.g., curly quotes).\n",
        "- **Perform lemmatization** to reduce words to their base form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUmZWeqzO3_m",
        "outputId": "c4885743-de82-4b7e-87c6-70f0ba404757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji\n",
        "\n",
        "import re\n",
        "import emoji\n",
        "from nltk.corpus import stopwords\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6-6_f7VO3_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e933c018-3e9f-4219-d869-a27322b52820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "emojis_list = map(lambda x: ''.join(x.split()), emoji.EMOJI_DATA.keys())\n",
        "\n",
        "EMOJI_RE = re.compile('|'.join(re.escape(p) for p in emojis_list))\n",
        "HASHTAGS_RE = re.compile('#\\w+')\n",
        "MENTIONS_RE = re.compile('@\\w+')\n",
        "URL_RE = re.compile('(https|http)?:\\/\\/\\S+')\n",
        "#Qui ho aggiunto il punto sostituito dallo spazio perchè mi sembra che la maggior parte\n",
        "#dei tweets ne traggono beneficio, poi TODO va provato raga\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|,;‘’“”\\\"\\.]')\n",
        "SPECIAL_CHARACTERS_RE = re.compile('&amp;')\n",
        "GOOD_SYMBOLS_RE = re.compile('[^\\w+ +]')\n",
        "\n",
        "try:\n",
        "    STOPWORDS = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "    STOPWORDS = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiar3s09O3_n"
      },
      "outputs": [],
      "source": [
        "def lower(text: str) -> str:\n",
        "    return text.lower()\n",
        "\n",
        "def remove_emojis(text: str) -> str:\n",
        "    return EMOJI_RE.sub(' ',text)\n",
        "\n",
        "def remove_hashtags(text: str) -> str:\n",
        "    return HASHTAGS_RE.sub(' ', text)\n",
        "\n",
        "def remove_mentions(text: str) -> str:\n",
        "    return MENTIONS_RE.sub(' ', text)\n",
        "\n",
        "def remove_url(text: str) -> str:\n",
        "    return URL_RE.sub(' ',text)\n",
        "\n",
        "def remove_special_characters(text: str) -> str:\n",
        "    return SPECIAL_CHARACTERS_RE.sub('', text)\n",
        "\n",
        "def replace_special_characters(text: str) -> str:\n",
        "    return REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "\n",
        "def filter_out_uncommon_symbols(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes any special character that is not in the good symbols list (check regular expression)\n",
        "    \"\"\"\n",
        "    return GOOD_SYMBOLS_RE.sub('', text)\n",
        "\n",
        "def remove_stopwords(text: str) -> str:\n",
        "    return ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n",
        "\n",
        "def strip_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes any left or right spacing (including carriage return) from text.\n",
        "    \"\"\"\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncKwO6yO3_n"
      },
      "source": [
        "We can observe that some hashtags in the form \"#somethinghttps://\" also removes the initial part of the link."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAnHByb3O3_n"
      },
      "source": [
        "@rufinelix's account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXkeuKHpO3_o"
      },
      "outputs": [],
      "source": [
        "from typing import List, Callable, Dict\n",
        "from functools import reduce\n",
        "\n",
        "PREPROCESSING_PIPELINE = [\n",
        "                          lower,\n",
        "                          remove_emojis,\n",
        "                          remove_hashtags,\n",
        "                          remove_mentions,\n",
        "                          remove_url,\n",
        "                          remove_special_characters,\n",
        "                          replace_special_characters,\n",
        "                          filter_out_uncommon_symbols,\n",
        "                          remove_stopwords,\n",
        "                          strip_text\n",
        "                          ]\n",
        "#Lui elimina anche le stopwords, poi TODO va provato raga\n",
        "\n",
        "def text_prepare(text: str,\n",
        "                 filter_methods: List[Callable[[str], str]] = None) -> str:\n",
        "    \"\"\"\n",
        "    Applies a list of pre-processing functions in sequence (reduce).\n",
        "    Note that the order is important here!\n",
        "    \"\"\"\n",
        "    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n",
        "    return reduce(lambda txt, f: f(txt), filter_methods, text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmtdMboIO3_o",
        "outputId": "6b5f32c0-c7de-4d5c-abc1-ff364ccea44b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-processing text...\n",
            "\n",
            "[Debug] Before:\n",
            "According to a customer I have plenty of time to go spent the Stirling coins he wants to pay me with, in Derry. \"Just like any other woman, I'm sure of it.\" #EveryDaySexism in retail.\n",
            "\n",
            "[Debug] After:\n",
            "according customer plenty time go spent stirling coins wants pay derry like woman im sure retail\n",
            "\n",
            "Pre-processing completed!\n"
          ]
        }
      ],
      "source": [
        "print('Pre-processing text...')\n",
        "\n",
        "print()\n",
        "print(f'[Debug] Before:\\n{training_set.tweet.values[2]}')\n",
        "print()\n",
        "\n",
        "# Replace each sentence with its pre-processed version\n",
        "training_set['tweet'] = training_set['tweet'].apply(lambda txt: text_prepare(txt))\n",
        "validation_set['tweet'] = validation_set['tweet'].apply(lambda txt: text_prepare(txt))\n",
        "test_set['tweet'] = test_set['tweet'].apply(lambda txt: text_prepare(txt))\n",
        "\n",
        "print(f'[Debug] After:\\n{training_set.tweet.values[2]}')\n",
        "print()\n",
        "\n",
        "print(\"Pre-processing completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "ZWo94S5MO3_o",
        "outputId": "0e7ac84c-e69e-44a4-c475-f44a2a4ccce3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200002    writing uni essay local pub coffee random old ...\n",
              "200003    2021 1921 dont appreciate two rides team membe...\n",
              "200006    according customer plenty time go spent stirli...\n",
              "200007    blokes drink beer sorry arent bloke drink wine...\n",
              "200008       new shelves week looking forward reading books\n",
              "200010                      guess fairly normal neanderthal\n",
              "200011    means women usually end lower paid support wor...\n",
              "200013    hi orla interesting piece 2 policy response be...\n",
              "200015    dear god colette capable identifying sexism li...\n",
              "200016                            women home cooking family\n",
              "Name: tweet, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200002</th>\n",
              "      <td>writing uni essay local pub coffee random old ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200003</th>\n",
              "      <td>2021 1921 dont appreciate two rides team membe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200006</th>\n",
              "      <td>according customer plenty time go spent stirli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200007</th>\n",
              "      <td>blokes drink beer sorry arent bloke drink wine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200008</th>\n",
              "      <td>new shelves week looking forward reading books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200010</th>\n",
              "      <td>guess fairly normal neanderthal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200011</th>\n",
              "      <td>means women usually end lower paid support wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200013</th>\n",
              "      <td>hi orla interesting piece 2 policy response be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200015</th>\n",
              "      <td>dear god colette capable identifying sexism li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200016</th>\n",
              "      <td>women home cooking family</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#Focus Focus Focus qui le contrazioni tipo I'm le accorpa, ma sotto la lemmatization con wordNet le\n",
        "#scoppia. Se usassimo le stopwords le eliminerebbe direttamente e il problema non si porrebbe, quindi indovinate\n",
        "#TODO va provato raga\n",
        "training_set.iloc[:10]['tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_a7AzM6O3_o",
        "outputId": "0b41fbe2-e974-48b1-d6c8-23477a48f348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokenizer = WhitespaceTokenizer()\n",
        "\n",
        "def get_wordnet_key(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return 'n'\n",
        "\n",
        "def lem_text(text: str):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tagged = pos_tag(tokens)\n",
        "    words = [lemmatizer.lemmatize(word, get_wordnet_key(tag)) for word, tag in tagged]\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "Wa8xcbcAO3_o",
        "outputId": "658306e1-11c8-48d8-e88a-7bfda19115e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200002    writing uni essay local pub coffee random old ...\n",
              "200003    2021 1921 dont appreciate two rides team membe...\n",
              "200006    according customer plenty time go spent stirli...\n",
              "200007    blokes drink beer sorry arent bloke drink wine...\n",
              "200008       new shelves week looking forward reading books\n",
              "200010                      guess fairly normal neanderthal\n",
              "200011    means women usually end lower paid support wor...\n",
              "200013    hi orla interesting piece 2 policy response be...\n",
              "200015    dear god colette capable identifying sexism li...\n",
              "200016                            women home cooking family\n",
              "Name: tweet, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200002</th>\n",
              "      <td>writing uni essay local pub coffee random old ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200003</th>\n",
              "      <td>2021 1921 dont appreciate two rides team membe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200006</th>\n",
              "      <td>according customer plenty time go spent stirli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200007</th>\n",
              "      <td>blokes drink beer sorry arent bloke drink wine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200008</th>\n",
              "      <td>new shelves week looking forward reading books</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200010</th>\n",
              "      <td>guess fairly normal neanderthal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200011</th>\n",
              "      <td>means women usually end lower paid support wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200013</th>\n",
              "      <td>hi orla interesting piece 2 policy response be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200015</th>\n",
              "      <td>dear god colette capable identifying sexism li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200016</th>\n",
              "      <td>women home cooking family</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "training_set['tweet'][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPV1wPaGO3_p"
      },
      "outputs": [],
      "source": [
        "lem_train_texts = [lem_text(text) for text in training_set['tweet']]\n",
        "lem_validation_texts = [lem_text(text) for text in validation_set['tweet']]\n",
        "lem_test_texts = [lem_text(text) for text in test_set['tweet']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkFXXPRJO3_p",
        "outputId": "a58fd6e0-400b-4a2a-b577-51e93d744187"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['write uni essay local pub coffee random old man keep ask drunk question im try concentrate end good luck youll end get marry use anyway alive well',\n",
              " '2021 1921 dont appreciate two ride team member look behind ask man behind many party impress',\n",
              " 'accord customer plenty time go spent stirling coin want pay derry like woman im sure retail',\n",
              " 'bloke drink beer sorry arent bloke drink wine apparently alive well',\n",
              " 'new shelf week look forward read book',\n",
              " 'guess fairly normal neanderthal',\n",
              " 'mean woman usually end low pay support work start change traditionalist notice unfairness previously hasnt bother',\n",
              " 'hi orla interest piece 2 policy response believe earlyinlife prosecution punishment way go boy young men offend girl woman see zero tolerance approach institute',\n",
              " 'dear god colette capable identify sexism literally anywhere good see develop female grandpa simpson',\n",
              " 'woman home cooking family']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "lem_train_texts[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNzqL_0HO3_p"
      },
      "outputs": [],
      "source": [
        "training_set['tweet'] = lem_train_texts\n",
        "validation_set['tweet'] = lem_validation_texts\n",
        "test_set['tweet'] = lem_test_texts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the longest tweet\n",
        "longest_tweet = max(training_set['tweet'], key=lambda x: len(x.split()))\n",
        "longest_tweet_length = len(longest_tweet.split())\n",
        "\n",
        "print(f\"Longest tweet: {longest_tweet}\")\n",
        "print(f\"Length of the longest tweet: {longest_tweet_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHyiqAsswEBS",
        "outputId": "f70da249-18c9-49de-c92a-dd5c65d1bcce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest tweet: movie 103+ haunt tale 1980 + house 1977 + gift hate 2019 + ouijia japan 2021 + dream home 2010 + ghoul 2018 + ringu spiral 1998 + ringu 0 2000 + gaze 2014 + 3 2012 + daughter 2015 + roommate 2010\n",
            "Length of the longest tweet: 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AXZOPpcO3_p"
      },
      "source": [
        "<h1> Task 3 </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNOwfJzQO3_p"
      },
      "source": [
        "Embed words using **GloVe embeddings**. <br>\n",
        "You are **free** to pick any embedding dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46QHfuNOO3_p"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug25Ior2O3_q"
      },
      "outputs": [],
      "source": [
        "def build_vocabulary(df: pd.DataFrame) -> (Dict[int, str], Dict[str, int], List[str]):\n",
        "    \"\"\"\n",
        "    Given a dataset, builds the corresponding word vocabulary.\n",
        "\n",
        "    :param df: dataset from which we want to build the word vocabulary (pandas.DataFrame)\n",
        "    :return:\n",
        "      - word vocabulary: vocabulary index to word\n",
        "      - inverse word vocabulary: word to vocabulary index\n",
        "      - word listing: set of unique terms that build up the vocabulary\n",
        "    \"\"\"\n",
        "    idx_to_word = OrderedDict()\n",
        "    word_to_idx = OrderedDict()\n",
        "\n",
        "    curr_idx = 0\n",
        "    for sentence in df.tweet:\n",
        "        tokens = sentence.split()\n",
        "        for token in tokens:\n",
        "            if token not in word_to_idx:\n",
        "                word_to_idx[token] = curr_idx\n",
        "                idx_to_word[curr_idx] = token\n",
        "                curr_idx += 1\n",
        "\n",
        "    word_to_idx['UNK'] = curr_idx\n",
        "    idx_to_word[curr_idx] = 'UNK'\n",
        "\n",
        "    word_listing = list(idx_to_word.values())\n",
        "    return idx_to_word, word_to_idx, word_listing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsVDtwr1O3_q",
        "outputId": "e4cf11c7-b46a-4ba0-f064-c7131e519153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Debug] Index -> Word vocabulary size: 9363\n",
            "[Debug] Word -> Index vocabulary size: 9363\n",
            "[Debug] Some words: [('uni', 1), ('essay', 2), ('local', 3), ('pub', 4), ('coffee', 5), ('random', 6), ('old', 7), ('man', 8), ('keep', 9), ('ask', 10)]\n"
          ]
        }
      ],
      "source": [
        "idx_to_word, word_to_idx, word_listing = build_vocabulary(training_set)\n",
        "print(f'[Debug] Index -> Word vocabulary size: {len(idx_to_word)}')\n",
        "print(f'[Debug] Word -> Index vocabulary size: {len(word_to_idx)}')\n",
        "print(f'[Debug] Some words: {[(idx_to_word[idx], idx) for idx in np.arange(10) + 1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqLbEcDRO3_q"
      },
      "outputs": [],
      "source": [
        "idx_to_word, word_to_idx, word_listing = build_vocabulary(training_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPsCG_RhO3_q"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import gensim.downloader as gloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DduFQdEHO3_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b608f9c-0591-4e25-ab37-85904e63185a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ],
      "source": [
        "embedding_dimension = 50\n",
        "download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
        "emb_model = gloader.load(download_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J262jvDjO3_q"
      },
      "outputs": [],
      "source": [
        "def check_OOV_terms(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                    word_listing: List[str]):\n",
        "    \"\"\"\n",
        "    Checks differences between pre-trained embedding model vocabulary\n",
        "    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_listing: dataset specific vocabulary (list)\n",
        "\n",
        "    :return\n",
        "        - list of OOV terms\n",
        "    \"\"\"\n",
        "    embedding_vocabulary = set(embedding_model.key_to_index.keys())\n",
        "    oov = set(word_listing).difference(embedding_vocabulary)\n",
        "    return list(oov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntyweYSJO3_v",
        "outputId": "120466de-5efb-4429-edb3-a27bb1ef4c46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms: 1340 (14.31%)\n"
          ]
        }
      ],
      "source": [
        "oov_terms = check_OOV_terms(emb_model, word_listing)\n",
        "oov_percentage = float(len(oov_terms)) * 100 / len(word_listing)\n",
        "print(f\"Total OOV terms: {len(oov_terms)} ({oov_percentage:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Um9Gby5PO3_v"
      },
      "outputs": [],
      "source": [
        "def build_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                           embedding_dimension: int,\n",
        "                           word_to_idx: Dict[str, int],\n",
        "                           vocab_size: int,\n",
        "                           oov_terms: List[str]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Builds the embedding matrix of a specific dataset given a pre-trained word embedding model\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_to_idx: vocabulary map (word -> index) (dict)\n",
        "    :param vocab_size: size of the vocabulary\n",
        "    :param oov_terms: list of OOV terms (list)\n",
        "\n",
        "    :return\n",
        "        - embedding matrix that assigns a high dimensional vector to each word in the dataset specific vocabulary (shape |V| x d)\n",
        "    \"\"\"\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dimension), dtype=np.float32)\n",
        "    for word, idx in word_to_idx.items():\n",
        "        try:\n",
        "            embedding_vector = embedding_model[word]\n",
        "        except (KeyError, TypeError):\n",
        "            embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
        "\n",
        "        embedding_matrix[idx] = embedding_vector\n",
        "\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E06W4seQO3_v",
        "outputId": "3c1a7169-5dc6-4935-8f7a-c092bf9aa498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix shape: (9363, 50)\n"
          ]
        }
      ],
      "source": [
        "embedding_matrix = build_embedding_matrix(emb_model, embedding_dimension, word_to_idx, len(word_to_idx), oov_terms)\n",
        "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating an extra column for each dataset to store all the token ids"
      ],
      "metadata": {
        "id": "UzYggMVKm-7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(sentence: str, word_to_idx: Dict[str, int]) -> List[int]:\n",
        "    \"\"\"\n",
        "    Maps tokens in a sentence to vocabulary indices, replacing OOV terms with 'UNK'.\n",
        "\n",
        "    :param sentence: input sentence (str)\n",
        "    :param word_to_idx: word-to-index mapping (dict)\n",
        "    :return: list of token indices (list of int)\n",
        "    \"\"\"\n",
        "    tokens = sentence.split()\n",
        "    return [word_to_idx.get(token, word_to_idx['UNK']) for token in tokens]\n",
        "\n",
        "training_set['processed'] = training_set['tweet'].apply(\n",
        "    lambda x: preprocess_text(x, word_to_idx)\n",
        ")\n",
        "\n",
        "# Validation/Test: Preprocess to handle OOV terms\n",
        "validation_set['processed'] = validation_set['tweet'].apply(\n",
        "    lambda x: preprocess_text(x, word_to_idx)\n",
        ")\n",
        "test_set['processed'] = test_set['tweet'].apply(\n",
        "    lambda x: preprocess_text(x, word_to_idx)\n",
        ")\n",
        "\n",
        "# Inspect a test sentence\n",
        "print(\"Original:\", test_set['tweet'].iloc[0])\n",
        "print(\"Processed indices:\", test_set['processed'].iloc[0])\n",
        "print(\"Embedding for 'UNK':\", embedding_matrix[word_to_idx['UNK']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNOO6ZDgItPu",
        "outputId": "c43ba26c-e1e3-43f0-e5c9-f0c63c8e23ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: 1st day pool beautiful sunday ny bad dare go due frigid water temp last 45 min figure prove point\n",
            "Processed indices: [5076, 299, 9094, 1952, 1176, 2871, 432, 2310, 43, 668, 4916, 4763, 4990, 1055, 9362, 2277, 775, 479, 534]\n",
            "Embedding for 'UNK': [-0.03142696 -0.02820361 -0.04649735 -0.00534922  0.03183896  0.02778227\n",
            "  0.01973962 -0.04577972 -0.03505006  0.0077349  -0.00177013 -0.03875668\n",
            " -0.03643844 -0.01867991 -0.01501157  0.04914561 -0.00635848 -0.04044833\n",
            "  0.01972314  0.02004857 -0.02953106  0.0062747  -0.01541279  0.04354129\n",
            " -0.04249245  0.04879354  0.04115901 -0.0001555   0.03107064 -0.01114116\n",
            "  0.01895882 -0.0068631   0.03873672  0.00570616  0.0005564   0.03316834\n",
            "  0.04781918 -0.02131381 -0.04992817 -0.03114495 -0.03101544 -0.00393728\n",
            "  0.02920229  0.00197864  0.04202003 -0.00961925  0.04498549 -0.04077271\n",
            "  0.042126    0.0129231 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set['processed']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "olw_dH8TaB-L",
        "outputId": "c2f41c51-912d-4a73-98d4-7acb9d4a56e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200002    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...\n",
              "200003    [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 10, 8...\n",
              "200006    [39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5...\n",
              "200007         [54, 55, 56, 57, 58, 54, 55, 59, 60, 24, 25]\n",
              "200008                         [61, 62, 63, 34, 64, 65, 66]\n",
              "                                ...                        \n",
              "203256    [902, 271, 523, 1084, 1708, 1827, 1919, 34, 50...\n",
              "203257    [263, 3537, 13, 990, 1098, 2181, 1362, 6513, 3...\n",
              "203258    [623, 361, 705, 188, 1151, 13, 6401, 370, 6380...\n",
              "203259                                 [34, 50, 2238, 9360]\n",
              "203260       [5278, 9361, 370, 34, 50, 2238, 34, 1919, 835]\n",
              "Name: processed, Length: 2870, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200002</th>\n",
              "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200003</th>\n",
              "      <td>[26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 10, 8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200006</th>\n",
              "      <td>[39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200007</th>\n",
              "      <td>[54, 55, 56, 57, 58, 54, 55, 59, 60, 24, 25]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200008</th>\n",
              "      <td>[61, 62, 63, 34, 64, 65, 66]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203256</th>\n",
              "      <td>[902, 271, 523, 1084, 1708, 1827, 1919, 34, 50...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203257</th>\n",
              "      <td>[263, 3537, 13, 990, 1098, 2181, 1362, 6513, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203258</th>\n",
              "      <td>[623, 361, 705, 188, 1151, 13, 6401, 370, 6380...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203259</th>\n",
              "      <td>[34, 50, 2238, 9360]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203260</th>\n",
              "      <td>[5278, 9361, 370, 34, 50, 2238, 34, 1919, 835]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2870 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0vfIQTxbJ2O",
        "outputId": "2af88977-5f19-4570-85e9-7c1a9a7fa40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.065611  ,  0.18878   ,  0.38947   , ...,  0.50332   ,\n",
              "        -0.37874   ,  0.78717   ],\n",
              "       [-0.48424   ,  0.10052   , -0.20392   , ...,  0.528     ,\n",
              "         0.47025   , -0.099937  ],\n",
              "       [-0.73514   ,  1.0877    , -1.0185    , ...,  0.40231   ,\n",
              "         0.07081   ,  0.24598   ],\n",
              "       ...,\n",
              "       [ 0.94112   ,  0.072009  ,  0.054059  , ..., -1.035     ,\n",
              "        -0.1885    ,  0.35589   ],\n",
              "       [ 0.17566   ,  0.40873   , -0.3003    , ..., -0.67123   ,\n",
              "        -0.91092   ,  0.88043   ],\n",
              "       [-0.03142696, -0.02820361, -0.04649735, ..., -0.04077271,\n",
              "         0.042126  ,  0.0129231 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElRAMGFAO3_w"
      },
      "source": [
        "## TASK 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v5aNs3fO3_w"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
        "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
        "\n",
        "* **Model 1**: add an additional LSTM layer to the Baseline model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnIgIG7CO3_w"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM, Bidirectional, Dense, Embedding, TimeDistributed\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import f1_score\n",
        "import tensorflow as tf\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Padding sentences to achieve the same length for each of them\n",
        "TODO: padding dynamically within each batch"
      ],
      "metadata": {
        "id": "BDXkjQa-mw9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = longest_tweet_length  # Define a fixed maximum sequence length\n",
        "train_padded = pad_sequences(training_set['processed'], maxlen=max_length, padding='post')\n",
        "validation_padded = pad_sequences(validation_set['processed'], maxlen=max_length, padding='post')\n",
        "test_padded = pad_sequences(test_set['processed'], maxlen=max_length, padding='post')"
      ],
      "metadata": {
        "id": "nGR4UQoverNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_padded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj4aFtbAYUvw",
        "outputId": "4fabc2cf-915e-4bee-9e92-fec5b22fb035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2870, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining embedding layer"
      ],
      "metadata": {
        "id": "nYb7k_4VYHel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_to_idx)\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "                            input_dim=vocab_size,\n",
        "                            output_dim=embedding_dimension,\n",
        "                            weights=[embedding_matrix],\n",
        "                            mask_zero=True,                # automatically masks padding tokens\n",
        "                            name='encoder_embedding'\n",
        "                            #trainable=False               # default: learnable params\n",
        "                            )"
      ],
      "metadata": {
        "id": "x9H1_nySYEmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title - working directly with the embeddings"
      ],
      "metadata": {
        "id": "A9yx4GJ_Dgky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA_MgEuqO3_w"
      },
      "outputs": [],
      "source": [
        "#@title - working with the Embedding Layer\n",
        "# defining a bidirectional LSTM\n",
        "def create_model(name, hidden_units=64, activation=\"sigmoid\", extra_LSTM=False):\n",
        "    model = Sequential()\n",
        "    model.add(embedding_layer)\n",
        "    model.add(Bidirectional(LSTM(hidden_units, return_sequences=False)))\n",
        "\n",
        "    # add an extra LSTM layer for Model 1\n",
        "    if extra_LSTM:\n",
        "      model.add(LSTM(hidden_units, return_sequences=False))\n",
        "\n",
        "    model.add(Dense(1, activation=activation))\n",
        "    model.name = name\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5\n",
        "Training and evaluating Baseline and Model 1"
      ],
      "metadata": {
        "id": "hNaNfN8cJqpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\"baseline\", \"model_1\"]"
      ],
      "metadata": {
        "id": "nsXL6AfoS4qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, seed, training_data, training_labels, val_data, val_labels, epochs = 10, batch_size = 32):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'precision', 'recall']) #binary loss because we have a binary classification task\n",
        "    history = model.fit(training_data, training_labels, epochs=epochs, batch_size=batch_size, validation_data=(val_data, val_labels))\n",
        "\n",
        "    # evaluate the model using the supported metrics\n",
        "    val_results = model.evaluate(val_data, val_labels, verbose=0)\n",
        "\n",
        "    val_loss = val_results[0]\n",
        "    val_accuracy = val_results[1]\n",
        "    val_precision = val_results[2]\n",
        "    val_recall = val_results[3]\n",
        "\n",
        "    # evaluate also using f1-macro\n",
        "    val_predictions = model.predict(val_data)\n",
        "    val_predictions = (val_predictions > 0.5).astype(int)  # binarize predictions\n",
        "    val_f1_macro = f1_score(val_labels, val_predictions, average='macro')\n",
        "\n",
        "    return history, val_loss, val_accuracy, val_precision, val_recall, val_f1_macro"
      ],
      "metadata": {
        "id": "kyj_-nygNJKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define seed list and hyperparams\n",
        "seeds = [39, 42, 777]\n",
        "hyperparams = {\n",
        "    \"hidden_units\": [32, 64],\n",
        "    \"batch_size\": [16, 32],\n",
        "}\n",
        "\n",
        "# Initialize the results dict. to store results for each model\n",
        "results = {model_name: [] for model_name in models}\n",
        "\n",
        "# Generate combinations of hyperparameters\n",
        "hyperparam_combinations = product(hyperparams[\"hidden_units\"], hyperparams[\"activation\"])\n",
        "\n",
        "# Loop over each model and hyperparameter combination\n",
        "for model_name in models:\n",
        "    print(f\"Showing results for the following model: {model_name}\")\n",
        "\n",
        "    # Iterate over all possible combinations of hyperparams\n",
        "    for hidden_units, batch_size in hyperparam_combinations:\n",
        "        print(f\"Testing with hidden_units={hidden_units} and batch_size={batch_size}\")\n",
        "\n",
        "        # Create the specified model with the current hyperparams\n",
        "        model = create_model(model_name, hidden_units=hidden_units, batch_size=batch_size)\n",
        "                if model_name == \"baseline\"\n",
        "                else create_model(model_name, hidden_units=hidden_units, extra_LSTM=True)\n",
        "\n",
        "        # Iterate over different seeds\n",
        "        for seed in seeds:\n",
        "            print(f\"Seed {seed}\")\n",
        "\n",
        "            # Train the model and get the results\n",
        "            history, val_loss, val_accuracy, val_precision, val_recall, val_f1_macro = train_model(\n",
        "                model, seed, train_padded, training_set['hard_label_task1'],\n",
        "                validation_padded, validation_set['hard_label_task1'], batch_size\n",
        "            )\n",
        "\n",
        "            # Store the results in the dict\n",
        "            results[model_name].append({\n",
        "                \"seed\": seed,\n",
        "                \"hidden_units\": hidden_units,\n",
        "                \"activation\": activation,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"val_accuracy\": val_accuracy,\n",
        "                \"val_precision\": val_precision,\n",
        "                \"val_recall\": val_recall,\n",
        "                \"val_f1_macro\": val_f1_macro,\n",
        "                \"history\": history\n",
        "            })"
      ],
      "metadata": {
        "id": "QP3mCUJPQwL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5-Z2N9xyFajW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}