{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Task 1 </h1>\n",
    "<h3> 2. Load the three JSON files and encode them as pandas dataframes. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = '/Users/kor/Desktop/Unibo/II year/Fall/NLP/Project/Assignment 1/data/test.json'\n",
    "training_url = '/Users/kor/Desktop/Unibo/II year/Fall/NLP/Project/Assignment 1/data/training.json'\n",
    "validation_url = '/Users/kor/Desktop/Unibo/II year/Fall/NLP/Project/Assignment 1/data/validation.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_json(training_url, orient='index')\n",
    "validation_set = pd.read_json(validation_url, orient='index')\n",
    "test_set = pd.read_json(test_url, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3. Generate hard labels for Task 1 using majority voting and store them in a new dataframe column called `hard_label_task1`. <br>Items without a clear majority will be removed from the dataset. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority(l):\n",
    "    y_count = l.count('YES')\n",
    "    n_count = l.count('NO')\n",
    "\n",
    "    if y_count == n_count:\n",
    "        return pd.NaT\n",
    "    \n",
    "    if y_count > 3:\n",
    "        return 'YES'\n",
    "\n",
    "    return 'NO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['hard_label_task1'] = training_set['labels_task1'].apply(majority)\n",
    "training_set.dropna(axis=0, inplace=True)\n",
    "\n",
    "validation_set['hard_label_task1'] = validation_set['labels_task1'].apply(majority)\n",
    "validation_set.dropna(axis=0, inplace=True)\n",
    "\n",
    "test_set['hard_label_task1'] = test_set['labels_task1'].apply(majority)\n",
    "test_set.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4. Filter the DataFrame to keep only rows where the `lang` column is `'en'`. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = training_set[training_set['lang'] == lang]\n",
    "validation_set = validation_set[validation_set['lang'] == lang]\n",
    "test_set = test_set[test_set['lang'] == lang]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 5. Remove unwanted columns: Keep only `id_EXIST`, `lang`, `tweet`, and `hard_label_task1`. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = training_set.loc[:,['id_EXIST', 'lang', 'tweet', 'hard_label_task1']]\n",
    "validation_set = validation_set.loc[:,['id_EXIST', 'lang', 'tweet', 'hard_label_task1']]\n",
    "test_set = test_set.loc[:,['id_EXIST', 'lang', 'tweet', 'hard_label_task1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 6. Encode the `hard_label_task1` column: Use 1 to represent \"YES\" and 0 to represent \"NO\".</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['hard_label_task1'] = training_set['hard_label_task1'].map({'YES':1, 'NO':0})\n",
    "validation_set['hard_label_task1'] = validation_set['hard_label_task1'].map({'YES':1, 'NO':0})\n",
    "test_set['hard_label_task1'] = test_set['hard_label_task1'].map({'YES':1, 'NO':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hard_label_task1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200002</th>\n",
       "      <td>200002</td>\n",
       "      <td>en</td>\n",
       "      <td>Writing a uni essay in my local pub with a cof...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200003</th>\n",
       "      <td>200003</td>\n",
       "      <td>en</td>\n",
       "      <td>@UniversalORL it is 2021 not 1921. I dont appr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200006</th>\n",
       "      <td>200006</td>\n",
       "      <td>en</td>\n",
       "      <td>According to a customer I have plenty of time ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200007</th>\n",
       "      <td>200007</td>\n",
       "      <td>en</td>\n",
       "      <td>So only 'blokes' drink beer? Sorry, but if you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200008</th>\n",
       "      <td>200008</td>\n",
       "      <td>en</td>\n",
       "      <td>New to the shelves this week - looking forward...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203256</th>\n",
       "      <td>203256</td>\n",
       "      <td>en</td>\n",
       "      <td>idk why y’all bitches think having half your a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203257</th>\n",
       "      <td>203257</td>\n",
       "      <td>en</td>\n",
       "      <td>This has been a part of an experiment with @Wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203258</th>\n",
       "      <td>203258</td>\n",
       "      <td>en</td>\n",
       "      <td>\"Take me already\" \"Not yet. You gotta be ready...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203259</th>\n",
       "      <td>203259</td>\n",
       "      <td>en</td>\n",
       "      <td>@clintneedcoffee why do you look like a whore?...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203260</th>\n",
       "      <td>203260</td>\n",
       "      <td>en</td>\n",
       "      <td>ik when mandy says “you look like a whore” i l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2870 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_EXIST lang                                              tweet  \\\n",
       "200002    200002   en  Writing a uni essay in my local pub with a cof...   \n",
       "200003    200003   en  @UniversalORL it is 2021 not 1921. I dont appr...   \n",
       "200006    200006   en  According to a customer I have plenty of time ...   \n",
       "200007    200007   en  So only 'blokes' drink beer? Sorry, but if you...   \n",
       "200008    200008   en  New to the shelves this week - looking forward...   \n",
       "...          ...  ...                                                ...   \n",
       "203256    203256   en  idk why y’all bitches think having half your a...   \n",
       "203257    203257   en  This has been a part of an experiment with @Wo...   \n",
       "203258    203258   en  \"Take me already\" \"Not yet. You gotta be ready...   \n",
       "203259    203259   en  @clintneedcoffee why do you look like a whore?...   \n",
       "203260    203260   en  ik when mandy says “you look like a whore” i l...   \n",
       "\n",
       "        hard_label_task1  \n",
       "200002                 1  \n",
       "200003                 1  \n",
       "200006                 1  \n",
       "200007                 1  \n",
       "200008                 0  \n",
       "...                  ...  \n",
       "203256                 1  \n",
       "203257                 1  \n",
       "203258                 1  \n",
       "203259                 1  \n",
       "203260                 1  \n",
       "\n",
       "[2870 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Task 2 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Remove emojis** from the tweets.\n",
    "- **Remove hashtags** (e.g., `#example`).\n",
    "- **Remove mentions** such as `@user`.\n",
    "- **Remove URLs** from the tweets.\n",
    "- **Remove special characters and symbols**.\n",
    "- **Remove specific quote characters** (e.g., curly quotes).\n",
    "- **Perform lemmatization** to reduce words to their base form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis_list = map(lambda x: ''.join(x.split()), emoji.EMOJI_DATA.keys())\n",
    "\n",
    "EMOJI_RE = re.compile('|'.join(re.escape(p) for p in emojis_list))\n",
    "HASHTAGS_RE = re.compile('#\\w+')\n",
    "MENTIONS_RE = re.compile('@\\w+')\n",
    "URL_RE = re.compile('(https|http)?:\\/\\/\\S+')\n",
    "#Qui ho aggiunto il punto sostituito dallo spazio perchè mi sembra che la maggior parte \n",
    "#dei tweets ne traggono beneficio, poi TODO va provato raga\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|,;‘’“”\\\"\\.]')\n",
    "SPECIAL_CHARACTERS_RE = re.compile('[&amp;]')\n",
    "GOOD_SYMBOLS_RE = re.compile('[^\\w+ +]')\n",
    "\n",
    "try:\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text: str) -> str:\n",
    "    return EMOJI_RE.sub(' ',text)\n",
    "\n",
    "def remove_hashtags(text: str) -> str:\n",
    "    return HASHTAGS_RE.sub(' ', text)\n",
    "\n",
    "def remove_mentions(text: str) -> str:\n",
    "    return MENTIONS_RE.sub(' ', text)\n",
    "\n",
    "def remove_url(text: str) -> str:\n",
    "    return URL_RE.sub(' ',text)\n",
    "\n",
    "def remove_special_characters(text: str) -> str:\n",
    "    return SPECIAL_CHARACTERS_RE.sub('', text)\n",
    "\n",
    "def replace_special_characters(text: str) -> str:\n",
    "    return REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "\n",
    "def filter_out_uncommon_symbols(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes any special character that is not in the good symbols list (check regular expression)\n",
    "    \"\"\"\n",
    "    return GOOD_SYMBOLS_RE.sub('', text)\n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    return ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n",
    "\n",
    "def strip_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes any left or right spacing (including carriage return) from text.\n",
    "    \"\"\"\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that some hashtags in the form \"#somethinghttps://\" also removes the initial part of the link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@rufinelix's account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable, Dict\n",
    "from functools import reduce\n",
    "\n",
    "PREPROCESSING_PIPELINE = [\n",
    "                          remove_emojis,\n",
    "                          remove_hashtags,\n",
    "                          remove_mentions,\n",
    "                          remove_url,\n",
    "                          remove_special_characters,\n",
    "                          replace_special_characters,\n",
    "                          filter_out_uncommon_symbols,\n",
    "                          strip_text\n",
    "                          ]\n",
    "#Lui elimina anche le stopwords, poi TODO va provato raga\n",
    "\n",
    "def text_prepare(text: str,\n",
    "                 filter_methods: List[Callable[[str], str]] = None) -> str:\n",
    "    \"\"\"\n",
    "    Applies a list of pre-processing functions in sequence (reduce).\n",
    "    Note that the order is important here!\n",
    "    \"\"\"\n",
    "    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n",
    "    return reduce(lambda txt, f: f(txt), filter_methods, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing text...\n",
      "\n",
      "[Debug] Before:\n",
      "According to a customer I have plenty of time to go spent the Stirling coins he wants to pay me with, in Derry. \"Just like any other woman, I'm sure of it.\" #EveryDaySexism in retail.\n",
      "\n",
      "[Debug] After:\n",
      "According to a customer I have plenty of time to go spent the Stirling coins he wants to pay me with  in Derry  Just like any other woman  Im sure of it    in retail\n",
      "\n",
      "Pre-processing completed!\n"
     ]
    }
   ],
   "source": [
    "print('Pre-processing text...')\n",
    "\n",
    "print()\n",
    "print(f'[Debug] Before:\\n{training_set.tweet.values[2]}')\n",
    "print()\n",
    "\n",
    "# Replace each sentence with its pre-processed version\n",
    "training_set['tweet'] = training_set['tweet'].apply(lambda txt: text_prepare(txt))\n",
    "validation_set['tweet'] = validation_set['tweet'].apply(lambda txt: text_prepare(txt))\n",
    "test_set['tweet'] = test_set['tweet'].apply(lambda txt: text_prepare(txt))\n",
    "\n",
    "print(f'[Debug] After:\\n{training_set.tweet.values[2]}')\n",
    "print()\n",
    "\n",
    "print(\"Pre-processing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200002    Writing a uni essay in my local pub with a cof...\n",
       "200003    it is 2021 not 1921 I dont appreciate that on ...\n",
       "200006    According to a customer I have plenty of time ...\n",
       "200007    So only blokes drink beer Sorry  but if you ar...\n",
       "200008    New to the shelves this week  looking forward ...\n",
       "200010       I guess that s fairly normal for a Neanderthal\n",
       "200011    means women usually end up in lower paid suppo...\n",
       "200013    Hi Orla Interesting piece On No 2 As a policy ...\n",
       "200015    Dear GodColette is capable of identifying sexi...\n",
       "200016    The women will all be at home cooking for the ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Focus Focus Focus qui le contrazioni tipo I'm le accorpa, ma sotto la lemmatization con wordNet le \n",
    "#scoppia. Se usassimo le stopwords le eliminerebbe direttamente e il problema non si porrebbe, quindi indovinate\n",
    "#TODO va provato raga\n",
    "training_set.iloc[:10]['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "\n",
    "def get_wordnet_key(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return 'n'\n",
    "\n",
    "def lem_text(text: str):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "    words = [lemmatizer.lemmatize(word, get_wordnet_key(tag)) for word, tag in tagged]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_train_texts = [lem_text(text) for text in training_set['tweet']]\n",
    "lem_validation_texts = [lem_text(text) for text in validation_set['tweet']]\n",
    "lem_test_texts = [lem_text(text) for text in test_set['tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Writing a uni essay in my local pub with a coffee Random old man keep ask me drunk question when Im try to concentrate amp end with good luck but youll just end up get married and not use it anyway be alive and well',\n",
       " 'it be 2021 not 1921 I dont appreciate that on two ride by myself your team member look behind me and ask the man behind how many in my party Not impressed',\n",
       " 'According to a customer I have plenty of time to go spent the Stirling coin he want to pay me with in Derry Just like any other woman Im sure of it in retail',\n",
       " 'So only blokes drink beer Sorry but if you arent a bloke you drink wine apparently alive and well in',\n",
       " 'New to the shelf this week look forward to read these book',\n",
       " 'I guess that s fairly normal for a Neanderthal',\n",
       " 'mean woman usually end up in low paid support work when that start to change traditionalist notice unfairness that previously hasnt bother them at all',\n",
       " 'Hi Orla Interesting piece On No 2 As a policy response do you believe earlyinlife prosecution and punishment be the way to go with boys young men when they offend against girl and woman Is this how you see by a zero tolerance approach be institute',\n",
       " 'Dear GodColette be capable of identify sexism literally anywhereGood to see develop their own female Grandpa Simpson',\n",
       " 'The woman will all be at home cooking for the family']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_train_texts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Task 3 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed words using **GloVe embeddings**. <br>\n",
    "You are **free** to pick any embedding dimension."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
